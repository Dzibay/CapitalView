import asyncio
import aiohttp
import random
from bs4 import BeautifulSoup
from datetime import datetime, date
from app.services.supabase_service import table_select, table_insert

# URL —Å—Ç—Ä–∞–Ω–∏—Ü
SMARTLAB_INDEX_URL = "https://smart-lab.ru/dividends/index/order_by_yield/desc/"
# –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ —Å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–º –¥–ª—è –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
SMARTLAB_HISTORY_BASE_URL = "https://smart-lab.ru/dividends/history/order_by_cut_off_date/desc/page{}/"

async def fetch_html(session, url):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º, —á—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä
        await asyncio.sleep(random.uniform(0.5, 1.5))
        
        async with session.get(url, headers=headers) as resp:
            if resp.status == 200:
                return await resp.text()
            elif resp.status == 404:
                print(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (404): {url}")
                return None
            else:
                print(f"‚ö†Ô∏è SmartLab ({url}) –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {resp.status}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
    return None

def parse_date(date_str):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞—Ç—É –∏–∑ '25.12.2025' –≤ –æ–±—ä–µ–∫—Ç date"""
    if not date_str or date_str == '-':
        return None
    try:
        return datetime.strptime(date_str.strip(), "%d.%m.%Y").date()
    except (ValueError, AttributeError):
        return None

def normalize_value(val_str):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É '9,17' –∏–ª–∏ '<strong>902</strong>' –≤ float"""
    if not val_str:
        return 0.0
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, —Ç–µ–≥–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
    clean_val = val_str.replace(',', '.').replace(' ', '').strip()
    try:
        return float("".join(c for c in clean_val if c.isdigit() or c == '.'))
    except ValueError:
        return 0.0

def parse_smartlab_row(row, mode="index"):
    """
    –ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã HTML.
    mode="index" ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –±—É–¥—É—â–∏—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤
    mode="history" ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏
    """
    cols = row.find_all("td")
    
    # –í —Ç–∞–±–ª–∏—Ü–µ –∏—Å—Ç–æ—Ä–∏–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å 10 –∏–ª–∏ 11 –∫–æ–ª–æ–Ω–æ–∫
    if len(cols) < 5:
        return None

    try:
        # –¢–∏–∫–µ—Ä –æ–±—ã—á–Ω–æ –≤–æ –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–µ [1], –Ω–æ –∏–Ω–æ–≥–¥–∞ –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–∫–∏
        ticker_col = cols[1]
        ticker = ticker_col.get_text(strip=True)
        
        if not ticker: 
            return None

        last_buy_date = None
        record_date = None
        payment_date = None
        value = 0.0
        dividend_yield = None

        value = normalize_value(cols[3].get_text(strip=True))
        dividend_yield = normalize_value(cols[4].get_text(strip=True))
        last_buy_date = parse_date(cols[6].get_text(strip=True))
        record_date = parse_date(cols[7].get_text(strip=True))
        payment_date = parse_date(cols[8].get_text(strip=True))

        # –û–±—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏: –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ö–æ—Ç—å –æ–¥–Ω–∞ –¥–∞—Ç–∞
        if not record_date and not payment_date and not last_buy_date:
            return None

        return {
            "ticker": ticker.upper(),
            'last_buy_date': last_buy_date,
            "record_date": record_date,
            "payment_date": payment_date,
            "value": value,
            'dividend_yield': dividend_yield
        }
    except Exception as e:
        # print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ ({mode}): {e}")
        return None

async def process_page(session, url, mode, ticker_map):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    # print(f"‚è≥ –°–∫–∞—á–∏–≤–∞–µ–º {url}...")
    html = await fetch_html(session, url)
    if not html:
        return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏

    soup = BeautifulSoup(html, "lxml")
    table = soup.find("table", class_="trades-table")
    
    if not table:
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –∫–æ–Ω–µ—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        return []

    tbody = table.find("tbody")
    if not tbody:
        return []

    parsed_items = []
    rows = tbody.find_all("tr")
    
    for row in rows:
        item = parse_smartlab_row(row, mode=mode)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–∞–∫–æ–π —Ç–∏–∫–µ—Ä —É –Ω–∞—Å –≤ –±–∞–∑–µ
        if item and item["ticker"] in ticker_map:
            item["asset_id"] = ticker_map[item["ticker"]]
            parsed_items.append(item)
            
    return parsed_items

async def update_forecasts():
    # 1. –ü–æ–ª—É—á–∞–µ–º ID –∞–∫—Ç–∏–≤–æ–≤
    assets = await asyncio.to_thread(table_select, "assets")
    ticker_map = {a["ticker"].upper(): a["id"] for a in assets if a.get("ticker")}
    
    # 2. –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤—ã–ø–ª–∞—Ç—ã (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å)
    existing_payouts = await asyncio.to_thread(table_select, "asset_payouts")
    
    # –ö–ª—é—á —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏: (asset_id, record_date, value)
    existing_keys = set()
    for p in existing_payouts:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –æ—Ç—Å–µ—á–∫–∏ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –Ω–æ –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç - payment_date
        date_key = str(p.get("record_date") or p.get("payment_date"))
        val = float(p["value"] or 0)
        existing_keys.add((p["asset_id"], date_key, val))

    all_items = []

    async with aiohttp.ClientSession() as session:
        # 3. –°–∫–∞—á–∏–≤–∞–µ–º –ë–£–î–£–©–ò–ï –¥–∏–≤–∏–¥–µ–Ω–¥—ã (–æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞)
        print("üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥—É—â–∏—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤...")
        future_items = await process_page(session, SMARTLAB_INDEX_URL, "index", ticker_map)
        if future_items:
            all_items.extend(future_items)

        # 4. –°–∫–∞—á–∏–≤–∞–µ–º –ò–°–¢–û–†–ò–Æ (–º–Ω–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü)
        print("üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤...")
        page_num = 1
        max_errors = 3 # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
        error_count = 0

        while True:
            url = SMARTLAB_HISTORY_BASE_URL.format(page_num)
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}...", end="\r")
            
            history_items = await process_page(session, url, "history", ticker_map)
            
            # –ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª—Å—è None (–æ—à–∏–±–∫–∞ 404 –∏–ª–∏ —Å–µ—Ç–∏) –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ - –≤—ã—Ö–æ–¥–∏–º
            if history_items is None:
                error_count += 1
                if error_count >= max_errors:
                    break
            elif len(history_items) == 0:
                # –ü—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞ - –∑–Ω–∞—á–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—á–∏–ª–∏—Å—å
                break
            else:
                all_items.extend(history_items)
                error_count = 0 # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
            
            page_num += 1
            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å –Ω–∞ —Å–ª—É—á–∞–π —Å–±–æ—è, —á—Ç–æ–±—ã –Ω–µ –ø–∞—Ä—Å–∏—Ç—å –≤–µ—á–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 50 —Å—Ç—Ä–∞–Ω–∏—Ü)
            if page_num > 60: 
                break

    print(f"\nüìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(all_items)}")

    # 5. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
    payouts_to_insert = []
    
    for item in all_items:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–∞—Ç—ã –¥–ª—è –∫–ª—é—á–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏: Record -> Payment -> Buy
        check_date = item["record_date"] or item["payment_date"] or item["last_buy_date"]
        
        if not check_date:
            continue

        key = (item["asset_id"], check_date.isoformat(), float(item["value"]))

        if key in existing_keys:
            continue
        
        existing_keys.add(key)

        new_payout = {
            "asset_id": item["asset_id"],
            "value": item["value"],
            'dividend_yield': item['dividend_yield'],
            "last_buy_date": item["last_buy_date"].isoformat() if item["last_buy_date"] else None,
            "record_date": item["record_date"].isoformat() if item["record_date"] else None,
            "payment_date": item["payment_date"].isoformat() if item["payment_date"] else None,
            "type": "dividend"
        }
        
        payouts_to_insert.append(new_payout)

    # 6. –ü–∞–∫–µ—Ç–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ (Batch Insert)
    added_count = 0
    BATCH_SIZE = 1000  # –†–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏

    if payouts_to_insert:
        print(f"üì¶ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –≤—Å—Ç–∞–≤–∫—É {len(payouts_to_insert)} –∑–∞–ø–∏—Å–µ–π...")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞–∫–µ—Ç—ã
        for i in range(0, len(payouts_to_insert), BATCH_SIZE):
            batch = payouts_to_insert[i : i + BATCH_SIZE]
            try:
                # table_insert –æ–±—ã—á–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å—Ç–∞–≤–∫—É —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π
                await asyncio.to_thread(table_insert, "asset_payouts", batch)
                print(f"   ‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω –ø–∞–∫–µ—Ç {i // BATCH_SIZE + 1} ({len(batch)} –∑–∞–ø–∏—Å–µ–π)")
                added_count += len(batch)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –ø–∞–∫–µ—Ç–∞ {i // BATCH_SIZE + 1}: {e}")
    else:
        print("üì≠ –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

    print(f"üèÅ –ì–æ—Ç–æ–≤–æ. –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {added_count}")

if __name__ == "__main__":
    asyncio.run(update_forecasts())